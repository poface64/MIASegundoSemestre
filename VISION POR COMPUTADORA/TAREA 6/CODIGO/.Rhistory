#### Expansión limpia del programa para hacer LDA multiclases ####
# Generar la matriz #
X = datos2[,-1]
Y = datos2[,1]
# Entra la matriz X
X = as.matrix(X)
X
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
# Varianza entre clases de la matriz #
Sb = St-Sw
# Armando la matriz de varianzas invertidas
S =  solve(Sw) %*% Sb
# Calcular los eigenvalores de la matriz
A = eigen(S)
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
# Eigenvectores para proyectar los datos en el nuevo espacio de k-1 dimensiones
DS = (VE>0.0001)
# Vectores seleccionados
SV = t(t(A$vectors[,DS]))
# Crear el vector de proyecciones k-1 dimensional
Z = X %*% SV
Z
colnames(Z) = paste0("ND",1:ncol(SV))
# Comprimir y reportar la salida
resu = list(varianza = VE,
coeficientes = SV,
proyecciones = Z)
View(resu$coeficientes)
modelo
A$values
SV
A$values[1]
t(t(A$vectors[,DS]))/A$values[1]
# Calcular los eigenvalores de la matriz
A = eigen(S)
A
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
VE
A$values[1]
SV = t(t(A$vectors[,DS]))/2
SV
#### Expansión limpia del programa para hacer LDA multiclases ####
# Generar la matriz #
X = datos2[,-1]
Y = datos2[,1]
X = datos[,1:2]
Y = datos[,3]
X = datos1[,-1]
Y = datos1[,1]
X
Y
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
m
St = (t(X)-m) %*% t(t(X)-m)
# Varianza entre clases de la matriz #
Sb = St-Sw
# Armando la matriz de varianzas invertidas
S =  solve(Sw) %*% Sb
# Calcular los eigenvalores de la matriz
A = eigen(S)
A
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
# Eigenvectores para proyectar los datos en el nuevo espacio de k-1 dimensiones
DS = (VE>0.0001)
# Vectores seleccionados
SV = t(t(A$vectors[,DS]))
# Crear el vector de proyecciones k-1 dimensional
Z = X %*% SV
colnames(Z) = paste0("ND",1:ncol(SV))
# Comprimir y reportar la salida
resu = list(varianza = VE,
coeficientes = SV,
proyecciones = Z)
resu
resu$coeficientes
# Aplicar el LDA que viene de formulazo #
modelo = lda(species~.,datos1)
modelo
View(resu$coeficientes)
modelo$scaling
modelo$scaling
X
X%*%modelo$scaling
plot(X%*%modelo$scaling,
pch = 16,
col = Y)
modelo$scaling
sum(modelo$scaling[,1]^2)
sum(modelo$scaling[,2]^2)
j = c(1.091229,0.1752418)
j/sum(j)
resu$varianza
resu$coeficientes[,1]
sum(resu$coeficientes[,1]^2)
sum(resu$coeficientes[,2]^2)
resu$coeficientes[,1]/sum(resu$coeficientes[,1]^2)
W = resu$coeficientes
W
W[,1]
Sw
t(W[,1])
t(t(W[,1]))
t(W[,1])%*%Sw%*%t(t(W[,1]))
sqrt(t(W[,1])%*%Sw%*%t(t(W[,1])))
W/sqrt(t(W[,1])%*%Sw%*%t(t(W[,1])))
W
W[,1]
W[,1]/sqrt(t(W[,1])%*%Sw%*%t(t(W[,1])))
sqrt(t(W[,1])%*%Sw%*%t(t(W[,1])))
a = sqrt(t(W[,1])%*%Sw%*%t(t(W[,1])))
W[,1]/a
a = as.numeric(sqrt(t(W[,1])%*%Sw%*%t(t(W[,1]))))
W[,1]/a
(W[,1]/a)>sum()
(W[,1]/a) |> sum()
round(resu$varianza)
round(A$values,6)
rm(list=ls())
# Cargar la base de datos y la libreria #
library(MASS)
library(palmerpenguins)
datos = as.data.frame(palmerpenguins::penguins)[,-c(2,7,8)]
datos1 = datos[is.na(datos$bill_length_mm)==F, ]
datos2 = datos1[datos1$species!="Gentoo",]
datos2$species = as.factor(as.character(datos2$species))
# Aplicar el LDA que viene de formulazo #
modelo = lda(species~.,datos1)
modelo
#### Expansión limpia del programa para hacer LDA multiclases ####
# Generar la matriz #
X = datos2[,-1]
Y = datos2[,1]
Y
X
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
medias
round(medias,4)
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
m
Sw
Sw
round(Sw,4)
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
round(St,4)
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
# Varianza entre clases de la matriz #
Sb = St-Sw
Sb
Y
Sb
round(Sb,4)
S =  solve(Sw) %*% Sb
round(S,4)
# Calcular los eigenvalores de la matriz
A = eigen(S)
round(A$values,4)
round(A$vectors,4)
round(A$vectors,4)[,1]
sum((round(A$vectors,4)[,1])^2)
sum((round(A$vectors,4)[,2])^2)
sum((round(A$vectors,4)[,3])^2)
sum((round(A$vectors,4)[,4])^2)
sum(A$vectors[,4])^2)
sum(A$vectors[,1]^2)
sum(A$vectors[,2]^2)
round(A$vectors)
round(A$vectors,4)
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
# Eigenvectores para proyectar los datos en el nuevo espacio de k-1 dimensiones
DS = (VE>0.0001)
# Vectores seleccionados
SV = t(t(A$vectors[,DS]))
DS
# Vectores seleccionados
SV = t(t(A$vectors[,DS]))
SV
# Crear el vector de proyecciones k-1 dimensional
Z = X %*% SV
colnames(Z) = paste0("ND",1:ncol(SV))
library(flextable)
Z1 = as.data.frame(Z)
Z1
flextable(Z1)
flextable(head(Z1))
X = datos1[,-1]
Y = datos1[,1]
# Entra la matriz X
X = as.matrix(X)
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
X
Y
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
round(medias,4)
Y
Y = datos2[,1]
Y
X = datos1[,-1]
Y = datos1[,1]
Y
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
St
round(medias,4)
clas[1]
clas[2]
round(medias,4)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
m
round(m,4)
names(m) = NULL
round(m,4)
round(Sw,4)
round(Sw,4)
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
Sw
dim(X)
X = datos2[,-1]
Y = datos2[,1]
X
dim(X)
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
St
X
dim(X)
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
round(St,4)
X1 = datos1[,-1]
Y1 = datos1[,1]
X2 = datos2[,-1]
Y2 = datos2[,1]
X1
Y1
X1 = datos1[,-1]
Y1 = datos1[,1]
m1 = colMeans(X1)
m1
m2 = colMeans(X2)
m2
X1 = datos1[,-1]
Y1 = datos1[,1]
m1 = colMeans(X1)
z1 = (t(X1)-m1) %*% t(t(X1)-m1)
X2 = datos2[,-1]
Y2 = datos2[,1]
m2 = colMeans(X2)
z2 = (t(X2)-m2) %*% t(t(X2)-m2)
dim(X2)
dim(X1)
round(z1,4)
round(z2,4)
X = datos1[,-1]
X = datos1[,-1]
Y = datos1[,1]
X
dim(x)
dim(X)
X = datos2[,-1]
Y = datos2[,1]
X
dim(X)
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
Sw
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
St
X
dim(X)
m2
m
(t(X)-m) %*% t(t(X)-m)
X2
(t(X2)-m2) %*% t(t(X2)-m2)
X2 = datos2[,-1]
Y2 = datos2[,1]
m2 = colMeans(X2)
z2 = (t(X2)-m2) %*% t(t(X2)-m2)
z2
X1 = datos1[,-1]
Y1 = datos1[,1]
m1 = colMeans(X1)
z1 = (t(X1)-m1) %*% t(t(X1)-m1)
z1
X = datos1[,-1]
Y = datos1[,1]
# Entra la matriz X
X = as.matrix(X)
#### Generar la matriz de medias ####
nc = ncol(X) # Numero P de variables
clas = unique(Y) # K Clases
nr = length(clas)  # Cantidad K de clases
medias = matrix(0,nr,nc) # Matriz de medias vacia
Sw = matrix(0,nc,nc) # Matriz de varianza Sw vacia
for(i in 1:nr){
# Separar los datos por clase #
mini1 = X[Y==clas[i],] # Subconjunto para la clase k-esima
# Calcular las medias
medias[i,] = colMeans(mini1) # Vector de medias K-esimo
# Calcular las matrices de covarianzas
Sn = (t(mini1)-medias[i,]) %*% t(t(mini1)-medias[i,]) #Matriz de varianza k-esima
# Acumuar la varianza
Sw = Sw + Sn # Matriz de dispersión dentro de la clase
}
# Dispersión total de los datos #
m = colMeans(X) # Vector de medias global
St = (t(X)-m) %*% t(t(X)-m)
# Varianza entre clases de la matriz #
Sb = St-Sw
# Armando la matriz de varianzas invertidas
S =  solve(Sw) %*% Sb
# Calcular los eigenvalores de la matriz
A = eigen(S)
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
St
z1 = (t(X1)-m1) %*% t(t(X1)-m1)
z1
# Varianza entre clases de la matriz #
Sb = St-Sw
Sb
# Armando la matriz de varianzas invertidas
S =  solve(Sw) %*% Sb
round(S,4)
# Armando la matriz de varianzas invertidas
S =  solve(Sw) %*% Sb
# Calcular los eigenvalores de la matriz
A = eigen(S)
round(A$values)
round(A$values,4)
round(A$vectors,4)
plot(datos1[,3],datos1[,2],pch = 16,col = datos1$species)
plot(datos1[,3],datos1[,4],pch = 16,col = datos1$species)
plot(datos1[,3],datos1[,5],pch = 16,col = datos1$species)
plot(datos1[,3],datos1[,2],pch = 16,col = datos1$species)
plot(datos1[,4],datos1[,2],pch = 16,col = datos1$species)
plot(datos1[,5],datos1[,2],pch = 16,col = datos1$species)
# Varianza explicada con los eigenvalores
VE = round(100*A$values/sum(A$values),4)
VE
